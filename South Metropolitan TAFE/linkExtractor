from requests import get
from bs4 import BeautifulSoup
import time

'''Collect links'''

links = []
links2 = []
links3 = []
#get the first set of links
url = 'https://www.southmetrotafe.wa.edu.au/'
request = get(url, headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'})
soup = BeautifulSoup(request.text, 'html.parser')
#print(soup.prettify())

ul_tag = soup.find(class_='tb-megamenu-subnav mega-nav level-2 items-13')
a_tag = ul_tag.find_all('a')
for a in a_tag:
    link = a.get('href')
    links.append(link)
    #print(link)

#get the socond set of links
for x in range(len(links)):
    url2 = 'https://www.southmetrotafe.wa.edu.au'+links[x]
    request2 = get(url2, headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'})
    soup2 = BeautifulSoup(request2.text, 'html.parser')
    #print(soup2.prettify())

    table_tag = soup2.find('table', class_='tablesorter')
    tbody = table_tag.find('tbody')
    tr_tag = tbody.find_all('tr')
    for tr in tr_tag:
        td_tag = tr.find('td', class_='c-course-title')
        link2 = td_tag.find('a').get('href')
        print(link2)
        links2.append(link2)
        links2 = list(dict.fromkeys(links2))

#write to file
with open('links.txt', 'w') as output:
    for row in links2:
        output.write(str(row)+'\n')